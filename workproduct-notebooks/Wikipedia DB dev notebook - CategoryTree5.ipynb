{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE\n",
    "# cypher.forbid_exhaustive_shortestpath=true set in neo4j conf file\n",
    "# https://neo4j.com/docs/operations-manual/current/configuration/neo4j-conf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodeInfo(a):\n",
    "    commandToRun = 'MATCH (pages:Page {id: %s}) \\\n",
    "                RETURN pages' % (a)\n",
    "    return graph.run(commandToRun).data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return similarity statistics for two sets (intersection, union, Jaccard coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute similarity statistics\n",
    "def similarityStats(a,b):\n",
    "    intSize = len(a.intersection(b))\n",
    "    unionSize = len(a.union(b))\n",
    "    \n",
    "    if unionSize == 0:\n",
    "        jaccard = 0\n",
    "    else:\n",
    "        jaccard = intSize / unionSize\n",
    "    \n",
    "    return (intSize, unionSize, jaccard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return identifying information of parent categories of chosen article or category as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give wikipedia id as integer as function argument (e.g. cateogry \"Finland\" = 693995)\n",
    "def parentCategories(a):\n",
    "    wikiID = a\n",
    "    commandToRun = 'MATCH (pages:Category:Page) \\\n",
    "                <-[:BELONGS_TO]- \\\n",
    "                (:Page {id: %s}) \\\n",
    "                RETURN pages.title, pages.id' % (wikiID)\n",
    "\n",
    "    # ensure that a dataframe with correct columns is returnd also when query is empty\n",
    "    out = pd.DataFrame(columns = [\"pages.title\", \"pages.id\"])\n",
    "    out = out.append(graph.run(commandToRun).to_data_frame())\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return identifying information of children (both category and article) of chosen category as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give wikipedia id as integer as function argument (e.g. cateogry \"Finland\" = 693995)\n",
    "def childPages(a):\n",
    "    wikiID = a\n",
    "    commandToRun = 'MATCH (pages:Page) \\\n",
    "                -[:BELONGS_TO]-> \\\n",
    "                (:Page {id: %s}) \\\n",
    "                RETURN pages.title, pages.id' % (wikiID)\n",
    "\n",
    "    # ensure that a dataframe with correct columns is returnd also when query is empty\n",
    "    out = pd.DataFrame(columns = [\"pages.title\", \"pages.id\"])\n",
    "    out = out.append(graph.run(commandToRun).to_data_frame())\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return dataframe with all articles (but not categories) with given title [only one result is expected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give wikipedia title as string as function argument\n",
    "def articleByTitle(a):\n",
    "    ArticleToFind = a\n",
    "    commandToRun = 'MATCH (articles:Page {title: \"%s\"}) \\\n",
    "                    WHERE NONE(art IN [articles] WHERE art:Category) \\\n",
    "                    RETURN articles.title, articles.id, ID(articles)' % (ArticleToFind)\n",
    "    return graph.run(commandToRun).to_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return dataframe with all categories (but not articles) with given title [only one result is expected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give wikipedia title as string as function argument\n",
    "def categoryByTitle(a):\n",
    "    CategoryToFind = a\n",
    "    commandToRun = 'MATCH (categories:Category:Page {title: \"%s\"}) \\\n",
    "                    RETURN categories.title, categories.id, ID(categories)' % (CategoryToFind)\n",
    "    return graph.run(commandToRun).to_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return dataframe containing shortest path between input node (article or category) and Main_topics_classification category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortestPathToMTC(a):\n",
    "    # (:Page {id: 7345184}) is Main_topics_classifications category node\n",
    "    inputNode = a\n",
    "\n",
    "    commandToRun = 'MATCH path=shortestPath( \\\n",
    "                    (:Page {id: %s})-[:BELONGS_TO*0..10]->(:Page {id: 7345184})) \\\n",
    "                    UNWIND nodes(path) AS pages \\\n",
    "                    RETURN pages.title, pages.id, ID(pages)' % (inputNode)\n",
    "\n",
    "    return pd.DataFrame(graph.run(commandToRun).data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return similarity value between two categories as defined by Biuk-Aghai & Cheang (2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take as input tuple containing depth of category to compare to as well as intersection of children between two categories\n",
    "\n",
    "'''\n",
    "Given parent category p and child category c,\n",
    "and given a root category node r, we calculate the category similarity\n",
    "Sp;c as: Sp;c = Dc - Cp;c / k , where Dc is the depth of category\n",
    "c in the category graph, i.e. the shortest distance from the root\n",
    "category node r; Cp;c is the number of co-assigned articles of categories\n",
    "p and c; and k is a constant that is empirically determined.\n",
    "Through experimentation we have found that a value of k = 2 produces\n",
    "the best results, i.e. results that agree with human intuition as\n",
    "to similarity of a given pair of categories. A smaller value of Sp;c\n",
    "indicates a greater similarity (i.e. a smaller distance between the\n",
    "nodes). The number of co-assigned articles Cp;c of parent category\n",
    "p and child category c is simply the cardinality of the intersection\n",
    "of their assigned article sets: Cp;c = jAp \\ Acj, where Ap and Ac\n",
    "are the sets of articles assigned to categories p and c, respectively.\n",
    "'''\n",
    "# Depth is calcualted for parent when going bottom-up in graph\n",
    "# C is calculated using intersection of both child articles and sub-categories\n",
    "\n",
    "def similarityBAC(a):\n",
    "    d = a[0]\n",
    "    c = a[1]\n",
    "    k = 2\n",
    "    return d - (c/k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return dataframe containing all parent categories of category a and similarity statistics to each as well as parent depth to MTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give wikipedia id as integer as function argument (e.g. cateogry \"Finland\" = 693995)\n",
    "def parentSimilarities(a):\n",
    "    parents = parentCategories(a)\n",
    "    children = childPages(a)\n",
    "    \n",
    "    if len(parents) == 0:\n",
    "        raise ValueError(\"Category processed does not have parents (likely input category to chosenPathUpToMTC() if called)\")\n",
    "    \n",
    "    # Create columns with similarity stats using functions similarityStats\n",
    "    parents[\"similarities\"] = parents[\"pages.id\"].apply(lambda x: similarityStats(set(children[\"pages.id\"]), set(childPages(x)[\"pages.id\"])))\n",
    "    parents[[\"intersection\", \"union\", \"jaccard\"]] = pd.DataFrame(parents['similarities'].tolist(), index = parents.index)\n",
    "    parents.drop([\"similarities\"], axis = 1, inplace = True)\n",
    "        \n",
    "    # Add column with parent category depth (steps to Main_topics_classifications node)\n",
    "    parents[\"depth\"] = parents[\"pages.id\"].apply(lambda x: len(shortestPathToMTC(x))-1)\n",
    "    \n",
    "    # Add column with similarityBAC\n",
    "    parents[\"similarityBAC-aid\"] = list(zip(parents[\"depth\"], parents[\"intersection\"]))\n",
    "    parents[\"similarityBAC\"] = parents[\"similarityBAC-aid\"].apply(lambda x: similarityBAC(x))\n",
    "    parents.drop([\"similarityBAC-aid\"], axis = 1, inplace = True)\n",
    "    \n",
    "    # Sort ascending\n",
    "    parents.sort_values(by = \"similarityBAC\", ascending = True, inplace = True)\n",
    "    parents.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return node based on neo4j database ID [NOTE: not same as wikipedia ID used elsewhere]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWithNeoID(a):\n",
    "    return NodeMatcher(graph).get(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return dataframe containing info of what category to choose from parentSimilarities() output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "we choose which parent link to keep according to\n",
    "following rules: (1) Choose the parent whose similarity value Sp;c\n",
    "is lower; (2) If Sp1;c = Sp2;c, choose the parent whose depth D is\n",
    "lower; (3) If Dp1 = Dp2, choose the parent with the larger value\n",
    "of Cp;c; (4) If Cp1;c = Cp2;c, choose the parent with the lower\n",
    "page ID.\n",
    "'''\n",
    "# Takes parentSimilarities() / or potentially child similarities output dataframe as input\n",
    "def chooseCategoryPath(a):\n",
    "    a.sort_values(by = [\"similarityBAC\", \"depth\"], ascending = True, inplace = True)\n",
    "    a[\"mostSimilar\"] = \"False\"\n",
    "    a[\"comment\"] = \"\"\n",
    "    \n",
    "    # Set value for mostSimilar to \"Not connected\" for rows with depth = -1 i.e. no connection to MTC\n",
    "    a.loc[a[\"depth\"] == -1, \"comment\"] = \"Not connected\"\n",
    "    \n",
    "    # Set value for mostSimilar to \"True\" for rows that are not \"Not connected\" and that have the minimum value of similarityBAC\n",
    "    workingDF = a.loc[a[\"comment\"] != \"Not connected\"]\n",
    "    selectedIndexes = workingDF.loc[workingDF[\"similarityBAC\"] == workingDF[\"similarityBAC\"].min()].index\n",
    "    \n",
    "    a.loc[selectedIndexes, \"mostSimilar\"] = \"True\"\n",
    "    a.loc[selectedIndexes, \"comment\"] = \"Lowest similarityBAC\"\n",
    "    \n",
    "    workingDF = a.loc[a[\"mostSimilar\"] == \"True\"]\n",
    "    \n",
    "    if len(workingDF) > 1:\n",
    "        # Set all mostSimilar of partial dataframe and output back to False, then set min depth rows to true\n",
    "        workingDF[\"mostSimilar\"] = \"False\"\n",
    "        a[\"mostSimilar\"] = \"False\"\n",
    "        selectedIndexes = workingDF.loc[workingDF[\"depth\"] == workingDF[\"depth\"].min()].index\n",
    "        \n",
    "        a.loc[selectedIndexes, \"mostSimilar\"] = \"True\"\n",
    "        a.loc[selectedIndexes, \"comment\"] = a.loc[selectedIndexes, \"comment\"] + \"; Lowest depth\"\n",
    "        \n",
    "        workingDF = a.loc[a[\"mostSimilar\"] == \"True\"]\n",
    "        \n",
    "        # If several rows now set to true, test for highest intersection\n",
    "        if len(workingDF) > 1:\n",
    "            # Set all mostSimilar of partial dataframe and output back to False, then set max intersection rows to true\n",
    "            workingDF[\"mostSimilar\"] = \"False\"\n",
    "            a[\"mostSimilar\"] = \"False\"\n",
    "            selectedIndexes = workingDF.loc[workingDF[\"intersection\"] == workingDF[\"intersection\"].max()].index\n",
    "            \n",
    "            a.loc[selectedIndexes, \"mostSimilar\"] = \"True\"\n",
    "            a.loc[selectedIndexes, \"comment\"] = a.loc[selectedIndexes, \"comment\"] + \"; Highest intersection\"\n",
    "            \n",
    "            workingDF = a.loc[a[\"mostSimilar\"] == \"True\"]\n",
    "            \n",
    "            # If several rows now set to true, choose row with lowes pages.id\n",
    "            if len(workingDF) > 1:\n",
    "                # Set all mostSimilar of partial dataframe and output back to False, then set min wikipedia id row (only one) to true\n",
    "                workingDF[\"mostSimilar\"] = \"False\"\n",
    "                a[\"mostSimilar\"] = \"False\"\n",
    "                selectedIndexes = workingDF.loc[workingDF[\"pages.id\"] == workingDF[\"pages.id\"].min()].index\n",
    "                \n",
    "                a.loc[selectedIndexes, \"mostSimilar\"] = \"True\"\n",
    "                a.loc[selectedIndexes, \"comment\"] = a.loc[selectedIndexes, \"comment\"] + \"; Lowest wikipedia id\"\n",
    "    \n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return dataframe containing info of chosen path to MTC (iterates chooseCategoryPath() upwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate chooseCategoryPath() from input category (wikipedia id as input) until MTC is reached. Return dataframe with chosen path rows\n",
    "# Root node category \"Main_topic_classifications\" has pages.id = 7345184\n",
    "\n",
    "# NOTE: Error if input category does not have parents\n",
    "def chosenPathUpToMTC(a):\n",
    "    mtcFound = False\n",
    "    nextStep = a\n",
    "    chosenPath = pd.DataFrame()\n",
    "    \n",
    "    while(not mtcFound):\n",
    "        allParents = parentSimilarities(nextStep)\n",
    "        allParents = chooseCategoryPath(allParents)\n",
    "        \n",
    "        # If allParents contains MTC category\n",
    "        if(len(allParents.loc[allParents[\"pages.id\"] == 7345184]) == 1):\n",
    "            rowToAppend = allParents.loc[allParents[\"pages.id\"] == 7345184]\n",
    "            mtcFound = True\n",
    "        else:\n",
    "            rowToAppend = allParents.loc[allParents[\"mostSimilar\"] == \"True\"]\n",
    "            nextStep = int(allParents.loc[allParents[\"mostSimilar\"] == \"True\", \"pages.id\"])\n",
    "        \n",
    "        chosenPath = chosenPath.append(rowToAppend)\n",
    "        chosenPath.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "    return chosenPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Article strength calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return dataframe with all pages linking to or from input page\n",
    "def linksBetween(a):\n",
    "    wikiID = a\n",
    "    commandToRun = 'MATCH (pages:Page) \\\n",
    "                -[:LINKS_TO]- \\\n",
    "                (:Page {id: %s}) \\\n",
    "                RETURN pages.title, pages.id' % (wikiID)\n",
    "\n",
    "    # ensure that a dataframe with correct columns is returnd also when query is empty\n",
    "    out = pd.DataFrame(columns = [\"pages.title\", \"pages.id\"])\n",
    "    out = out.append(graph.run(commandToRun).to_data_frame())\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a as pages.id for artice, c as pages.id for parent category\n",
    "def articleClassificationStrength(a, c):\n",
    "    aLinks = set(linksBetween(a)[\"pages.id\"])\n",
    "    cChildren = set(childPages(c)[\"pages.id\"])\n",
    "    \n",
    "    intersectionSize = len(aLinks.intersection(cChildren))\n",
    "    \n",
    "    return 1 + intersectionSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strongestArticleParents(a):\n",
    "    parents = parentCategories(a)\n",
    "    parents[\"depth\"] = parents[\"pages.id\"].apply(lambda x: len(shortestPathToMTC(x)) -1 )\n",
    "    parents.loc[parents[\"depth\"] != -1 , \"Strength\"] = parents[\"pages.id\"].apply(lambda x: articleClassificationStrength(a, x))\n",
    "    parents.sort_values(by = [\"Strength\"], ascending = False, inplace = True)\n",
    "   \n",
    "    \n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chosenPathArticleToMTC(a):\n",
    "    strongestParent = strongestArticleParents(a)\n",
    "    path = chosenPathUpToMTC(strongestParent.iloc[0,1])\n",
    "    \n",
    "    path.loc[-1] = strongestParent.iloc[0, :3]\n",
    "    path.sort_index(inplace = True)\n",
    "    path.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding node labels and properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database edits (run commands commented out to prevent accidental runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add isCategory property with value 1 to all category pages\n",
    "\n",
    "commandToRun = 'MATCH (pages:Category:Page) \\\n",
    "                SET pages.isCategory = 1'\n",
    "\n",
    "#graph.run(commandToRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add isCategory property with value 0 to all article pages\n",
    "\n",
    "commandToRun = 'MATCH (pages:Page) \\\n",
    "                WHERE NONE(art IN [pages] WHERE art:Category) \\\n",
    "                SET pages.isCategory = 0'\n",
    "\n",
    "#graph.run(commandToRun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Marking categories to drop and dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add label \"Include\" to all pages (Wall time: 24min 41s)\n",
    "# NOTE - Not used\n",
    "\n",
    "commandToRun = \"MATCH (pages:Page) \\\n",
    "                SET pages:Include\"\n",
    "\n",
    "#graph.run(commandToRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Remove label \"Include\" from pages included in list of categories to exclude (Wall time: 1min 33s)\n",
    "# NOTE - Could remove label Include from all nodes\n",
    "\n",
    "commandToRun = \"MATCH (pages:Category:Page) \\\n",
    "                WHERE \\\n",
    "                pages.title STARTS WITH 'Wikipedia_' \\\n",
    "                OR pages.title STARTS WITH '1' \\\n",
    "                OR pages.title STARTS WITH '2' \\\n",
    "                OR pages.title STARTS WITH '3' \\\n",
    "                OR pages.title STARTS WITH '4' \\\n",
    "                OR pages.title STARTS WITH '5' \\\n",
    "                OR pages.title STARTS WITH '6' \\\n",
    "                OR pages.title STARTS WITH '7' \\\n",
    "                OR pages.title STARTS WITH '8' \\\n",
    "                OR pages.title STARTS WITH '9' \\\n",
    "                OR pages.title STARTS WITH '0' \\\n",
    "                OR pages.title STARTS WITH 'List_of' \\\n",
    "                OR pages.title STARTS WITH 'All_articles' \\\n",
    "                OR pages.title STARTS WITH 'Articles_' \\\n",
    "                OR pages.title CONTAINS 'by_year' \\\n",
    "                OR pages.title CONTAINS 'of_the_year' \\\n",
    "                OR pages.title CONTAINS '_in_' \\\n",
    "                REMOVE pages:Include\"\n",
    "\n",
    "#graph.run(commandToRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add label \"Exclude\" to all pages to exclude (Wall time: 1min 31s)\n",
    "\n",
    "commandToRun = \"MATCH (pages:Category:Page) \\\n",
    "                WHERE \\\n",
    "                pages.title STARTS WITH 'Wikipedia_' \\\n",
    "                OR pages.title STARTS WITH '1' \\\n",
    "                OR pages.title STARTS WITH '2' \\\n",
    "                OR pages.title STARTS WITH '3' \\\n",
    "                OR pages.title STARTS WITH '4' \\\n",
    "                OR pages.title STARTS WITH '5' \\\n",
    "                OR pages.title STARTS WITH '6' \\\n",
    "                OR pages.title STARTS WITH '7' \\\n",
    "                OR pages.title STARTS WITH '8' \\\n",
    "                OR pages.title STARTS WITH '9' \\\n",
    "                OR pages.title STARTS WITH '0' \\\n",
    "                OR pages.title STARTS WITH 'List_of' \\\n",
    "                OR pages.title STARTS WITH 'All_articles' \\\n",
    "                OR pages.title STARTS WITH 'Articles_' \\\n",
    "                OR pages.title CONTAINS 'by_year' \\\n",
    "                OR pages.title CONTAINS 'of_the_year' \\\n",
    "                OR pages.title CONTAINS '_in_' \\\n",
    "                SET pages:Exclude\"\n",
    "\n",
    "#graph.run(commandToRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add label \"Exclude\" to all pages to exclude (Wall time: 6.69 s)\n",
    "\n",
    "commandToRun = \"MATCH (pages:Category:Page) \\\n",
    "                WHERE \\\n",
    "                pages.title CONTAINS '_categories' \\\n",
    "                OR pages.title = 'Webarchive_template_wayback_links' \\\n",
    "                SET pages:Exclude\"\n",
    "\n",
    "#graph.run(commandToRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add label \"Exclude\" to all pages to exclude (Wall time: 6.69 s)\n",
    "\n",
    "commandToRun = \"MATCH (pages:Category:Page) \\\n",
    "                WHERE \\\n",
    "                pages.title = 'People_by_status' \\\n",
    "                SET pages:Exclude\"\n",
    "\n",
    "#graph.run(commandToRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add label \"Exclude\" to all pages to exclude (Wall time:  s)\n",
    "\n",
    "commandToRun = \"MATCH (pages:Category:Page) \\\n",
    "                WHERE \\\n",
    "                pages.title = 'Categories_by_language' \\\n",
    "                SET pages:Exclude\"\n",
    "\n",
    "#graph.run(commandToRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# DETACH and DELETE all nodes with label Exclude, iterate using APOC (Wall time: 39min 21s)\n",
    "# https://neo4j.com/developer/kb/large-delete-transaction-best-practices-in-neo4j/\n",
    "\n",
    "commandToRun = \"CALL apoc.periodic.iterate('MATCH (pages:Exclude) \\\n",
    "                RETURN pages', \\\n",
    "                'DETACH DELETE pages', \\\n",
    "                {batchSize:1000}) \\\n",
    "                YIELD batches, total \\\n",
    "                RETURN batches, total\"\n",
    "\n",
    "#graph.run(commandToRun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add label \"Exclude\" to all pages to exclude (Wall time: 6.69 s)\n",
    "\n",
    "commandToRun = \"MATCH (pages:Category:Page) \\\n",
    "                WHERE \\\n",
    "                pages.title = 'Sources' \\\n",
    "                SET pages:Exclude\"\n",
    "\n",
    "#graph.run(commandToRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# DETACH and DELETE all nodes with label Exclude, iterate using APOC (Wall time: 39min 21s)\n",
    "# https://neo4j.com/developer/kb/large-delete-transaction-best-practices-in-neo4j/\n",
    "\n",
    "commandToRun = \"CALL apoc.periodic.iterate('MATCH (pages:Exclude) \\\n",
    "                RETURN pages', \\\n",
    "                'DETACH DELETE pages', \\\n",
    "                {batchSize:1000}) \\\n",
    "                YIELD batches, total \\\n",
    "                RETURN batches, total\"\n",
    "\n",
    "#graph.run(commandToRun)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changing relations to optimize category tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# HELPER COMMAND FOR INFO\n",
    "# Replace (People) - [BELONGS_TO] -> (MTC) relation with [BELONGS_TO_CUT]\n",
    "# MTC wikipedia-id: 7345184\n",
    "commandToRun = 'MATCH (mtc:Page {id: 7345184}) <-[r]- (linker:Page {id: 3260154}) \\\n",
    "                RETURN r'\n",
    "#graph.run(commandToRun).data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add [BELONGS_TO_CUT] relationship between MTC and People\n",
    "# MTC wikipedia-id: 7345184, People wikipedia-id: 691008\n",
    "commandToRun = 'MATCH (MTC:Page {id: 7345184}), (People:Page {id: 691008}) \\\n",
    "                CREATE (MTC) <-[:BELONGS_TO_CUT]- (People)'\n",
    "# graph.run(commandToRun).data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Remove [BELONGS_TO] relationship between MTC and People\n",
    "# MTC wikipedia-id: 7345184, People wikipedia-id: 691008\n",
    "commandToRun = 'MATCH (MTC:Page {id: 7345184}) <-[r:BELONGS_TO]- (People:Page {id: 691008}) \\\n",
    "                DELETE r'\n",
    "# graph.run(commandToRun).data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add [BELONGS_TO_CUT] relationship between MTC and World\n",
    "# MTC wikipedia-id: 7345184, World wikipedia-id: 3260154\n",
    "commandToRun = 'MATCH (MTC:Page {id: 7345184}), (World:Page {id: 3260154}) \\\n",
    "                CREATE (MTC) <-[:BELONGS_TO_CUT]- (World)'\n",
    "#graph.run(commandToRun).data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Remove [BELONGS_TO] relationship between MTC and World\n",
    "# MTC wikipedia-id: 7345184, World wikipedia-id: 3260154\n",
    "commandToRun = 'MATCH (MTC:Page {id: 7345184}) <-[r:BELONGS_TO]- (World:Page {id: 3260154}) \\\n",
    "                DELETE r'\n",
    "#graph.run(commandToRun).data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add [BELONGS_TO] relationship between MTC and Entertainment\n",
    "# MTC wikipedia-id: 7345184, Entertainment wikipedia-id: 693016\n",
    "commandToRun = 'MATCH (MTC:Page {id: 7345184}), (Entertainment:Page {id: 693016}) \\\n",
    "                CREATE (MTC) <-[:BELONGS_TO]- (Entertainment)'\n",
    "#graph.run(commandToRun).data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step B\n",
    "##### Calculate similarity between two categories (Note: not an article and a category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step A\n",
    "##### Article - Category relationship strength (TBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe calculate the article classification strength Ac;a of\\nan article a for a given category c as: Ac;a = 1+ Aa intersection Ac, where\\nAa is the set of articles linking to, or being linked to by, article a;\\nand Ac is the set of all articles classified under category c (the classification\\nof article a to category c is the initial number 1 on the\\nequation’s right-hand side).\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "We calculate the article classification strength Ac;a of\n",
    "an article a for a given category c as: Ac;a = 1+ Aa intersection Ac, where\n",
    "Aa is the set of articles linking to, or being linked to by, article a;\n",
    "and Ac is the set of all articles classified under category c (the classification\n",
    "of article a to category c is the initial number 1 on the\n",
    "equation’s right-hand side).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pages.title</th>\n",
       "      <th>pages.id</th>\n",
       "      <th>intersection</th>\n",
       "      <th>union</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>depth</th>\n",
       "      <th>similarityBAC</th>\n",
       "      <th>mostSimilar</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isan_geography_stubs</td>\n",
       "      <td>10006151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thailand_geography_stubs</td>\n",
       "      <td>1440492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Lowest similarityBAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asia_geography_stubs</td>\n",
       "      <td>1476648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Lowest similarityBAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geography_stubs</td>\n",
       "      <td>931823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Lowest similarityBAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geography</td>\n",
       "      <td>693800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Lowest similarityBAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Main_topic_classifications</td>\n",
       "      <td>7345184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Lowest similarityBAC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pages.title  pages.id  intersection  union  jaccard  depth  \\\n",
       "0        Isan_geography_stubs  10006151           NaN    NaN      NaN      5   \n",
       "1    Thailand_geography_stubs   1440492           0.0  395.0      0.0      4   \n",
       "2        Asia_geography_stubs   1476648           0.0  214.0      0.0      3   \n",
       "3             Geography_stubs    931823           0.0  162.0      0.0      2   \n",
       "4                   Geography    693800           0.0  140.0      0.0      1   \n",
       "5  Main_topic_classifications   7345184           0.0  118.0      0.0      0   \n",
       "\n",
       "   similarityBAC mostSimilar               comment  \n",
       "0            NaN         NaN                   NaN  \n",
       "1            4.0        True  Lowest similarityBAC  \n",
       "2            3.0        True  Lowest similarityBAC  \n",
       "3            2.0        True  Lowest similarityBAC  \n",
       "4            1.0        True  Lowest similarityBAC  \n",
       "5            0.0        True  Lowest similarityBAC  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ArticleTitle = \"Na_Klang_District\"\n",
    "chosenPathArticleToMTC(articleByTitle(ArticleTitle).iloc[0,1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.9 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pages.title</th>\n",
       "      <th>pages.id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American_male_film_actors</td>\n",
       "      <td>38422423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American_male_voice_actors</td>\n",
       "      <td>40168018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American_male_television_actors</td>\n",
       "      <td>38422437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Featured_articles</td>\n",
       "      <td>8966941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Living_people</td>\n",
       "      <td>3782398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Male_actors_from_Oklahoma</td>\n",
       "      <td>40437871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Producers_who_won_the_Best_Picture_Academy_Award</td>\n",
       "      <td>17659363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Male_actors_from_Missouri</td>\n",
       "      <td>40438093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>American_film_producers</td>\n",
       "      <td>3082434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>University_of_Missouri_School_of_Journalism_alumni</td>\n",
       "      <td>56567836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Use_mdy_dates_from_October_2015</td>\n",
       "      <td>47971976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>People_from_Shawnee,_Oklahoma</td>\n",
       "      <td>31298021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>American_agnostics</td>\n",
       "      <td>5749115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Volpi_Cup_winners</td>\n",
       "      <td>34664678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>People_from_Springfield,_Missouri</td>\n",
       "      <td>5751378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AC_with_14_elements</td>\n",
       "      <td>42483113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Infobox_person_using_alma_mater</td>\n",
       "      <td>57892925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>American_former_Protestants</td>\n",
       "      <td>38834258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Former_Baptists</td>\n",
       "      <td>19455019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Golden_Globe_Award-winning_producers</td>\n",
       "      <td>26167549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Best_Supporting_Actor_Golden_Globe_(film)_winners</td>\n",
       "      <td>15947721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           pages.title  pages.id\n",
       "0                            American_male_film_actors  38422423\n",
       "1                           American_male_voice_actors  40168018\n",
       "2                      American_male_television_actors  38422437\n",
       "3                                    Featured_articles   8966941\n",
       "4                                        Living_people   3782398\n",
       "5                            Male_actors_from_Oklahoma  40437871\n",
       "6     Producers_who_won_the_Best_Picture_Academy_Award  17659363\n",
       "7                            Male_actors_from_Missouri  40438093\n",
       "8                              American_film_producers   3082434\n",
       "9   University_of_Missouri_School_of_Journalism_alumni  56567836\n",
       "10                     Use_mdy_dates_from_October_2015  47971976\n",
       "11                       People_from_Shawnee,_Oklahoma  31298021\n",
       "12                                  American_agnostics   5749115\n",
       "13                                   Volpi_Cup_winners  34664678\n",
       "14                   People_from_Springfield,_Missouri   5751378\n",
       "15                                 AC_with_14_elements  42483113\n",
       "16                     Infobox_person_using_alma_mater  57892925\n",
       "17                         American_former_Protestants  38834258\n",
       "18                                     Former_Baptists  19455019\n",
       "19                Golden_Globe_Award-winning_producers  26167549\n",
       "20   Best_Supporting_Actor_Golden_Globe_(film)_winners  15947721"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ArticleTitle = \"Brad_Pitt\"\n",
    "parentCategories(articleByTitle(ArticleTitle).iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categoryByTitle(\"Vehicles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parentCategories(5523119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#childPages(4892515)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#childPages(722196)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
