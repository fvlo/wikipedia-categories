{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD\n",
    "# Batch run functionality\n",
    "    # Take rows not yet processed, run in batches, save after each batch\n",
    "# Improve cleaned format of final dataframe (column names and contents)\n",
    "# Write final category guess rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation, digits\n",
    "import re\n",
    "import ast\n",
    "import stopit\n",
    "from py2neo import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keyword to article title mapping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "redirects = pd.read_csv(\"F:/wikipedia-data/outputs/redirect.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "articles = pd.read_csv(\"F:/wikipedia-data/outputs/articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "articles.dropna(subset = [\"title\"], inplace = True)\n",
    "redirects.dropna(subset = [\"title\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "articles[\"titleLower\"] = articles[\"title\"].apply(lambda x: x.lower())\n",
    "redirects[\"titleLower\"] = redirects[\"title\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to neo4j database - start database separately\n",
    "graph = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set timeout-limit in seconds for database calls\n",
    "maxSearchTime = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trivia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t_data = pd.read_pickle(\"../workproduct-files/t_dataMaster-keywordsIdentified.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search term to wikipedia article name linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns wikipedia article formatted for database search, if not found, returns FALSE\n",
    "def inArticles(a):\n",
    "    match = articles.loc[articles[\"titleLower\"] == a.lower(), :]\n",
    "    if len(match) > 0:\n",
    "        return match.iloc[0, 1].replace(\" \", \"_\")\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns wikipedia article formatted for database search, if not found, returns FALSE\n",
    "def inRedirects(a):\n",
    "    match = redirects.loc[redirects[\"titleLower\"] == a.lower(), :]\n",
    "    if len(match) > 0:\n",
    "        return match.iloc[0, 2].replace(\" \", \"_\")\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get first link from article based on title (DB formatting). Return False if no links exist\n",
    "def getFirstLink(a):\n",
    "    #match will be a pandas series of len=1\n",
    "    match = articles.loc[articles[\"title\"] == a.replace(\"_\", \" \"), \"links\"]\n",
    "    \n",
    "    if len(match) > 0:\n",
    "        #Change first series value into list\n",
    "        asList = ast.literal_eval(match.iloc[0]) \n",
    "        #result = asList[0].replace(\" \", \"_\")\n",
    "        result = asList[0]\n",
    "        \n",
    "        #Take string only until |\n",
    "        result = re.sub(\"(\\|)(.+)\", '', result)\n",
    "        result = re.sub(\"(\\|)\", '', result)\n",
    "        \n",
    "        return result\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikipedia article name to neo4j database calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call database for category tree and parents of given wikipedia title\n",
    "@stopit.threading_timeoutable(default='Database call timed out (' + str(maxSearchTime) + ' seconds)')\n",
    "def getCategoryInfo(a):\n",
    "    # kill function if runs to long (>2min ?)\n",
    "        # https://stackoverflow.com/questions/14920384/stop-code-after-time-period\n",
    "        # https://pypi.org/project/stopit/#id14\n",
    "    \n",
    "    #result [wikipediID, path to MTC, parents]\n",
    "    result = []\n",
    "    \n",
    "    try:\n",
    "        articleID = articleByTitle(a).iloc[0,1]\n",
    "        parents = parentCategories(articleID)\n",
    "        \n",
    "        if \"Disambiguation_pages\" in parents[\"pages.title\"].values:\n",
    "            firstLink = getFirstLink(a)\n",
    "            return getWikipediaInfo(firstLink)\n",
    "        else:\n",
    "            path = chosenPathArticleToMTC(articleID)\n",
    "        \n",
    "        return [a, articleID, path, parents]\n",
    "    \n",
    "    except (IndexError, ValueError, TypeError, ClientError):\n",
    "        return \"Database call not successful (error)\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs search functions from given search term --> Output from wikipedia database\n",
    "def getWikipediaInfo(a):\n",
    "    \n",
    "    term = a.lower()\n",
    "    \n",
    "    out = inArticles(term)\n",
    "    if out != False:\n",
    "        return getCategoryInfo(out, timeout = maxSearchTime)\n",
    "    \n",
    "    out = inRedirects(term)\n",
    "    if out != False:\n",
    "        return getCategoryInfo(out, timeout = maxSearchTime)\n",
    "    \n",
    "    return \"Search term not found\"\n",
    "        \n",
    "    \n",
    "    # if search term is in articles\n",
    "        # Perform database search\n",
    "        # Return (WikipediaID, Category tree, Parent categories)\n",
    "    # else if search term is in redirects\n",
    "        # Perform database search\n",
    "        # Return (WikipediaID, Category tree, Parent categories)\n",
    "    # else return FALSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### neo4j database calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return node info based on wikipedia id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodeInfo(a):\n",
    "    commandToRun = 'MATCH (pages:Page {id: %s}) \\\n",
    "                RETURN pages' % (a)\n",
    "    return graph.run(commandToRun).data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return similarity statistics for two sets (intersection, union, Jaccard coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute similarity statistics\n",
    "def similarityStats(a,b):\n",
    "    intSize = len(a.intersection(b))\n",
    "    unionSize = len(a.union(b))\n",
    "    \n",
    "    if unionSize == 0:\n",
    "        jaccard = 0\n",
    "    else:\n",
    "        jaccard = intSize / unionSize\n",
    "    \n",
    "    return (intSize, unionSize, jaccard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return identifying information of parent categories of chosen article or category as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give wikipedia id as integer as function argument (e.g. cateogry \"Finland\" = 693995)\n",
    "def parentCategories(a):\n",
    "    wikiID = a\n",
    "    commandToRun = 'MATCH (pages:Category:Page) \\\n",
    "                <-[:BELONGS_TO]- \\\n",
    "                (:Page {id: %s}) \\\n",
    "                RETURN pages.title, pages.id' % (wikiID)\n",
    "\n",
    "    # ensure that a dataframe with correct columns is returnd also when query is empty\n",
    "    out = pd.DataFrame(columns = [\"pages.title\", \"pages.id\"])\n",
    "    out = out.append(graph.run(commandToRun).to_data_frame())\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return identifying information of children (both category and article) of chosen category as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give wikipedia id as integer as function argument (e.g. cateogry \"Finland\" = 693995)\n",
    "def childPages(a):\n",
    "    wikiID = a\n",
    "    commandToRun = 'MATCH (pages:Page) \\\n",
    "                -[:BELONGS_TO]-> \\\n",
    "                (:Page {id: %s}) \\\n",
    "                RETURN pages.title, pages.id' % (wikiID)\n",
    "\n",
    "    # ensure that a dataframe with correct columns is returnd also when query is empty\n",
    "    out = pd.DataFrame(columns = [\"pages.title\", \"pages.id\"])\n",
    "    out = out.append(graph.run(commandToRun).to_data_frame())\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return dataframe with all articles (but not categories) with given title [only one result is expected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give wikipedia title as string as function argument\n",
    "# Will not work if article title contains \"-character --> \"ClientError\". Escape fixes do not work, not worth debugging.\n",
    "def articleByTitle(a):\n",
    "    ArticleToFind = a\n",
    "    commandToRun = 'MATCH (articles:Page {title: \"%s\"}) \\\n",
    "                    WHERE NONE(art IN [articles] WHERE art:Category) \\\n",
    "                    RETURN articles.title, articles.id, ID(articles)' % (ArticleToFind)\n",
    "    return graph.run(commandToRun).to_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return dataframe with all categories (but not articles) with given title [only one result is expected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give wikipedia title as string as function argument\n",
    "def categoryByTitle(a):\n",
    "    CategoryToFind = a\n",
    "    commandToRun = 'MATCH (categories:Category:Page {title: \"%s\"}) \\\n",
    "                    RETURN categories.title, categories.id, ID(categories)' % (CategoryToFind)\n",
    "    return graph.run(commandToRun).to_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return dataframe containing shortest path between input node (article or category) and Main_topics_classification category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortestPathToMTC(a):\n",
    "    # (:Page {id: 7345184}) is Main_topics_classifications category node\n",
    "    inputNode = a\n",
    "\n",
    "    commandToRun = 'MATCH path=shortestPath( \\\n",
    "                    (:Page {id: %s})-[:BELONGS_TO*0..10]->(:Page {id: 7345184})) \\\n",
    "                    UNWIND nodes(path) AS pages \\\n",
    "                    RETURN pages.title, pages.id, ID(pages)' % (inputNode)\n",
    "\n",
    "    return pd.DataFrame(graph.run(commandToRun).data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return similarity value between two categories as defined by Biuk-Aghai & Cheang (2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take as input tuple containing depth of category to compare to as well as intersection of children between two categories\n",
    "\n",
    "'''\n",
    "Given parent category p and child category c,\n",
    "and given a root category node r, we calculate the category similarity\n",
    "Sp;c as: Sp;c = Dc - Cp;c / k , where Dc is the depth of category\n",
    "c in the category graph, i.e. the shortest distance from the root\n",
    "category node r; Cp;c is the number of co-assigned articles of categories\n",
    "p and c; and k is a constant that is empirically determined.\n",
    "Through experimentation we have found that a value of k = 2 produces\n",
    "the best results, i.e. results that agree with human intuition as\n",
    "to similarity of a given pair of categories. A smaller value of Sp;c\n",
    "indicates a greater similarity (i.e. a smaller distance between the\n",
    "nodes). The number of co-assigned articles Cp;c of parent category\n",
    "p and child category c is simply the cardinality of the intersection\n",
    "of their assigned article sets: Cp;c = jAp \\ Acj, where Ap and Ac\n",
    "are the sets of articles assigned to categories p and c, respectively.\n",
    "'''\n",
    "# Depth is calcualted for parent when going bottom-up in graph\n",
    "# C is calculated using intersection of both child articles and sub-categories\n",
    "\n",
    "def similarityBAC(a):\n",
    "    d = a[0]\n",
    "    c = a[1]\n",
    "    k = 2\n",
    "    return d - (c/k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return dataframe containing all parent categories of category a and similarity statistics to each as well as parent depth to MTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give wikipedia id as integer as function argument (e.g. cateogry \"Finland\" = 693995)\n",
    "def parentSimilarities(a):\n",
    "    parents = parentCategories(a)\n",
    "    children = childPages(a)\n",
    "    \n",
    "    if len(parents) == 0:\n",
    "        raise ValueError(\"Category processed does not have parents (likely input category to chosenPathUpToMTC() if called)\")\n",
    "    \n",
    "    # Create columns with similarity stats using functions similarityStats\n",
    "    parents[\"similarities\"] = parents[\"pages.id\"].apply(lambda x: similarityStats(set(children[\"pages.id\"]), set(childPages(x)[\"pages.id\"])))\n",
    "    parents[[\"intersection\", \"union\", \"jaccard\"]] = pd.DataFrame(parents['similarities'].tolist(), index = parents.index)\n",
    "    parents.drop([\"similarities\"], axis = 1, inplace = True)\n",
    "        \n",
    "    # Add column with parent category depth (steps to Main_topics_classifications node)\n",
    "    parents[\"depth\"] = parents[\"pages.id\"].apply(lambda x: len(shortestPathToMTC(x))-1)\n",
    "    \n",
    "    # Add column with similarityBAC\n",
    "    parents[\"similarityBAC-aid\"] = list(zip(parents[\"depth\"], parents[\"intersection\"]))\n",
    "    parents[\"similarityBAC\"] = parents[\"similarityBAC-aid\"].apply(lambda x: similarityBAC(x))\n",
    "    parents.drop([\"similarityBAC-aid\"], axis = 1, inplace = True)\n",
    "    \n",
    "    # Sort ascending\n",
    "    parents.sort_values(by = \"similarityBAC\", ascending = True, inplace = True)\n",
    "    parents.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return parents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return node based on neo4j database ID [NOTE: not same as wikipedia ID used elsewhere]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWithNeoID(a):\n",
    "    return NodeMatcher(graph).get(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return dataframe containing info of what category to choose from parentSimilarities() output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "we choose which parent link to keep according to\n",
    "following rules: (1) Choose the parent whose similarity value Sp;c\n",
    "is lower; (2) If Sp1;c = Sp2;c, choose the parent whose depth D is\n",
    "lower; (3) If Dp1 = Dp2, choose the parent with the larger value\n",
    "of Cp;c; (4) If Cp1;c = Cp2;c, choose the parent with the lower\n",
    "page ID.\n",
    "'''\n",
    "# Takes parentSimilarities() / or potentially child similarities output dataframe as input\n",
    "def chooseCategoryPath(a):\n",
    "    a.sort_values(by = [\"similarityBAC\", \"depth\"], ascending = True, inplace = True)\n",
    "    a[\"mostSimilar\"] = \"False\"\n",
    "    a[\"comment\"] = \"\"\n",
    "    \n",
    "    # Set value for mostSimilar to \"Not connected\" for rows with depth = -1 i.e. no connection to MTC\n",
    "    a.loc[a[\"depth\"] == -1, \"comment\"] = \"Not connected\"\n",
    "    \n",
    "    # Set value for mostSimilar to \"True\" for rows that are not \"Not connected\" and that have the minimum value of similarityBAC\n",
    "    workingDF = a.loc[a[\"comment\"] != \"Not connected\"]\n",
    "    selectedIndexes = workingDF.loc[workingDF[\"similarityBAC\"] == workingDF[\"similarityBAC\"].min()].index\n",
    "    \n",
    "    a.loc[selectedIndexes, \"mostSimilar\"] = \"True\"\n",
    "    a.loc[selectedIndexes, \"comment\"] = \"Lowest similarityBAC\"\n",
    "    \n",
    "    workingDF = a.loc[a[\"mostSimilar\"] == \"True\"]\n",
    "    \n",
    "    if len(workingDF) > 1:\n",
    "        # Set all mostSimilar of partial dataframe and output back to False, then set min depth rows to true\n",
    "        workingDF[\"mostSimilar\"] = \"False\"\n",
    "        a[\"mostSimilar\"] = \"False\"\n",
    "        selectedIndexes = workingDF.loc[workingDF[\"depth\"] == workingDF[\"depth\"].min()].index\n",
    "        \n",
    "        a.loc[selectedIndexes, \"mostSimilar\"] = \"True\"\n",
    "        a.loc[selectedIndexes, \"comment\"] = a.loc[selectedIndexes, \"comment\"] + \"; Lowest depth\"\n",
    "        \n",
    "        workingDF = a.loc[a[\"mostSimilar\"] == \"True\"]\n",
    "        \n",
    "        # If several rows now set to true, test for highest intersection\n",
    "        if len(workingDF) > 1:\n",
    "            # Set all mostSimilar of partial dataframe and output back to False, then set max intersection rows to true\n",
    "            workingDF[\"mostSimilar\"] = \"False\"\n",
    "            a[\"mostSimilar\"] = \"False\"\n",
    "            selectedIndexes = workingDF.loc[workingDF[\"intersection\"] == workingDF[\"intersection\"].max()].index\n",
    "            \n",
    "            a.loc[selectedIndexes, \"mostSimilar\"] = \"True\"\n",
    "            a.loc[selectedIndexes, \"comment\"] = a.loc[selectedIndexes, \"comment\"] + \"; Highest intersection\"\n",
    "            \n",
    "            workingDF = a.loc[a[\"mostSimilar\"] == \"True\"]\n",
    "            \n",
    "            # If several rows now set to true, choose row with lowes pages.id\n",
    "            if len(workingDF) > 1:\n",
    "                # Set all mostSimilar of partial dataframe and output back to False, then set min wikipedia id row (only one) to true\n",
    "                workingDF[\"mostSimilar\"] = \"False\"\n",
    "                a[\"mostSimilar\"] = \"False\"\n",
    "                selectedIndexes = workingDF.loc[workingDF[\"pages.id\"] == workingDF[\"pages.id\"].min()].index\n",
    "                \n",
    "                a.loc[selectedIndexes, \"mostSimilar\"] = \"True\"\n",
    "                a.loc[selectedIndexes, \"comment\"] = a.loc[selectedIndexes, \"comment\"] + \"; Lowest wikipedia id\"\n",
    "    \n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Return dataframe containing info of chosen path to MTC (iterates chooseCategoryPath() upwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate chooseCategoryPath() from input category (wikipedia id as input) until MTC is reached. Return dataframe with chosen path rows\n",
    "# Root node category \"Main_topic_classifications\" has pages.id = 7345184\n",
    "\n",
    "# NOTE: Error if input category does not have parents\n",
    "def chosenPathUpToMTC(a):\n",
    "    mtcFound = False\n",
    "    nextStep = a\n",
    "    chosenPath = pd.DataFrame()\n",
    "    \n",
    "    while(not mtcFound):\n",
    "        allParents = parentSimilarities(nextStep)\n",
    "        allParents = chooseCategoryPath(allParents)\n",
    "        \n",
    "        # If allParents contains MTC category\n",
    "        if(len(allParents.loc[allParents[\"pages.id\"] == 7345184]) == 1):\n",
    "            rowToAppend = allParents.loc[allParents[\"pages.id\"] == 7345184]\n",
    "            mtcFound = True\n",
    "        else:\n",
    "            rowToAppend = allParents.loc[allParents[\"mostSimilar\"] == \"True\"]\n",
    "            nextStep = int(allParents.loc[allParents[\"mostSimilar\"] == \"True\", \"pages.id\"])\n",
    "        \n",
    "        chosenPath = chosenPath.append(rowToAppend)\n",
    "        chosenPath.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "    return chosenPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Article strength calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return dataframe with all pages linking to or from input page\n",
    "def linksBetween(a):\n",
    "    wikiID = a\n",
    "    commandToRun = 'MATCH (pages:Page) \\\n",
    "                -[:LINKS_TO]- \\\n",
    "                (:Page {id: %s}) \\\n",
    "                RETURN pages.title, pages.id' % (wikiID)\n",
    "\n",
    "    # ensure that a dataframe with correct columns is returnd also when query is empty\n",
    "    out = pd.DataFrame(columns = [\"pages.title\", \"pages.id\"])\n",
    "    out = out.append(graph.run(commandToRun).to_data_frame())\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a as pages.id for artice, c as pages.id for parent category\n",
    "def articleClassificationStrength(a, c):\n",
    "    aLinks = set(linksBetween(a)[\"pages.id\"])\n",
    "    cChildren = set(childPages(c)[\"pages.id\"])\n",
    "    \n",
    "    intersectionSize = len(aLinks.intersection(cChildren))\n",
    "    \n",
    "    return 1 + intersectionSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strongestArticleParents(a):\n",
    "    parents = parentCategories(a)\n",
    "    parents[\"depth\"] = parents[\"pages.id\"].apply(lambda x: len(shortestPathToMTC(x)) -1 )\n",
    "    parents.loc[parents[\"depth\"] != -1 , \"Strength\"] = parents[\"pages.id\"].apply(lambda x: articleClassificationStrength(a, x))\n",
    "    parents.sort_values(by = [\"Strength\"], ascending = False, inplace = True)\n",
    "   \n",
    "    \n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chosenPathArticleToMTC(a):\n",
    "    strongestParent = strongestArticleParents(a)\n",
    "    path = chosenPathUpToMTC(strongestParent.iloc[0,1])\n",
    "    \n",
    "    path.loc[-1] = strongestParent.iloc[0, :3]\n",
    "    path.sort_index(inplace = True)\n",
    "    path.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run \"question to wikipedia category\" analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write batch processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take list with search terms\n",
    "# Run getWikipediaInfo() until search term works\n",
    "# If result is False (search term not found) or \"Database call not successful (error)\" (search term found but path to MTC not available)\n",
    "    # --> continue to next search term\n",
    "# Return [(categoriesFound (boolean)), [n x (search term used, result), [1 x successful output]]]\n",
    "\n",
    "def findQuestionCategories(a):\n",
    "    categoriesFound = False\n",
    "    result = []\n",
    "    getWikipediaInfo_out = [None, None, None, None]\n",
    "    toReturn = []\n",
    "    possibleFailureMessages = ('Search term not found', 'Database call timed out (' + str(maxSearchTime) + ' seconds)', 'Database call not successful (error)')\n",
    "    \n",
    "    for term in a:\n",
    "        termResult = getWikipediaInfo(term)        \n",
    "        \n",
    "        if termResult not in possibleFailureMessages:\n",
    "            categoriesFound = True\n",
    "            # CHANGE: NOT NECESSARY TO SAVE TERM\n",
    "            result.append( (\"SUCCESS\") )\n",
    "            getWikipediaInfo_out = termResult\n",
    "            break\n",
    "        else:\n",
    "            result.append( (termResult) )\n",
    "    \n",
    "    if len(result) == 0:\n",
    "        result.append( (\"NO SEARCH TERMS GIVEN\") )\n",
    "    \n",
    "    # Insert categorieFound  at start of toReturn\n",
    "    toReturn.append(categoriesFound)\n",
    "    toReturn.append(result)\n",
    "    toReturn.append(getWikipediaInfo_out)\n",
    "    \n",
    "    return toReturn\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "use = t_data.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-0b2f5f3b6b43>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  workingDF[\"mostSimilar\"] = \"False\"\n",
      "<ipython-input-26-0b2f5f3b6b43>:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  workingDF[\"mostSimilar\"] = \"False\"\n",
      "<ipython-input-26-0b2f5f3b6b43>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  workingDF[\"mostSimilar\"] = \"False\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run time for 7 rows: 38,2 seconds\n",
    "# Run time for 65 rows: 7min 31s\n",
    "# Run time for 108 rows: 13min 49s\n",
    "use[\"findQuestionCategories_Out\"] = use[\"searchTerms\"].apply(lambda x: findQuestionCategories(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fredi\\miniconda3\\envs\\data-analysis\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "C:\\Users\\Fredi\\miniconda3\\envs\\data-analysis\\lib\\site-packages\\pandas\\core\\frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# Explode result from findQuestionCategories() into columns: 'wikipediaSearchSuccessful', 'usedSearchTerm', 'wikipediaArticleTitle', 'wikipediaArticleID', 'categoryPath', 'parentCategories'\n",
    "use[['wikipediaSearchSuccessful','findQuestionCategories_meta', 'findQuestionCategories_result']] = pd.DataFrame(use[\"findQuestionCategories_Out\"].tolist(), index= use.index)\n",
    "use.drop(columns = [\"findQuestionCategories_Out\"], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "use[[\"wikipediaArticleTitle\", \"wikipediaArticleID\", \"categoryPath\", \"parentCategories\"]] = pd.DataFrame(use[\"findQuestionCategories_result\"].tolist(), index= use.index)\n",
    "use.drop(columns = [\"findQuestionCategories_result\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONS_id</th>\n",
       "      <th>CONS_question</th>\n",
       "      <th>CONS_answer</th>\n",
       "      <th>CONS_alt answers</th>\n",
       "      <th>CONS_category</th>\n",
       "      <th>CONS_alt categories - NOT USED</th>\n",
       "      <th>CONS_type-formulation</th>\n",
       "      <th>CONS_type-multipleChoice</th>\n",
       "      <th>ORIG_id</th>\n",
       "      <th>ORIG_question</th>\n",
       "      <th>ORIG_answer</th>\n",
       "      <th>ORIG_alt answers</th>\n",
       "      <th>ORIG_category</th>\n",
       "      <th>ORIG_alt categories</th>\n",
       "      <th>ORIG_difficulty</th>\n",
       "      <th>ORIG_type</th>\n",
       "      <th>Source</th>\n",
       "      <th>Duplicate_removed</th>\n",
       "      <th>namedEntities</th>\n",
       "      <th>nouns</th>\n",
       "      <th>searchTerms</th>\n",
       "      <th>wikipediaSearchSuccessful</th>\n",
       "      <th>findQuestionCategories_meta</th>\n",
       "      <th>wikipediaArticleTitle</th>\n",
       "      <th>wikipediaArticleID</th>\n",
       "      <th>categoryPath</th>\n",
       "      <th>parentCategories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tdb_0x000000</td>\n",
       "      <td>\"Now is the winter of our discontent\" is a line from which Shakespearian play?</td>\n",
       "      <td>Richard III</td>\n",
       "      <td>[Romeo and Juliet, Macbeth]</td>\n",
       "      <td>Art and literature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Question</td>\n",
       "      <td>True</td>\n",
       "      <td>tdb_0x000000</td>\n",
       "      <td>\"Now is the winter of our discontent\" is a line from which Shakespearian play?</td>\n",
       "      <td>0</td>\n",
       "      <td>[Richard III, Romeo and Juliet, Macbeth]</td>\n",
       "      <td>ART_AND_LITERATURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tdb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(winter, DATE), (Shakespearian, NORP)]</td>\n",
       "      <td>[[Now is the winter of our discontent, 0], [line, 280009597], [play, 150748333]]</td>\n",
       "      <td>[Now is the winter of our discontent, play, line]</td>\n",
       "      <td>True</td>\n",
       "      <td>[SUCCESS]</td>\n",
       "      <td>Richard_III_(play)</td>\n",
       "      <td>176961</td>\n",
       "      <td>pages.title  pages.id  intersection  union   jaccard  depth  \\\n",
       "0   English_Renaissance_plays   1034365           NaN    NaN       NaN      5   \n",
       "1               English_plays   3258485           3.0  703.0  0.004267      5   \n",
       "2               British_plays   1928104          10.0  759.0  0.013175      5   \n",
       "3               British_drama   1376798           3.0  534.0  0.005618      4   \n",
       "4        Drama_by_nationality  25776489           0.0   63.0  0.000000      3   \n",
       "5                       Drama    709071           0.0  115.0  0.000000      2   \n",
       "6                     Theatre    698600           8.0  225.0  0.035556      2   \n",
       "7             Performing_arts    991222          16.0  258.0  0.062016      2   \n",
       "8               Entertainment    693016          15.0  253.0  0.059289      1   \n",
       "9  Main_topic_classifications   7345184           0.0  148.0  0.000000      0   \n",
       "\n",
       "   similarityBAC mostSimilar                             comment  \n",
       "0            NaN         NaN         ...</td>\n",
       "      <td>pages.title  pages.id\n",
       "0   Use_British_English_from_February_2013  38379146\n",
       "1              Plays_about_English_royalty  42128233\n",
       "2  Cultural_depictions_of_English_monarchs  15621221\n",
       "3                  Shakespearean_histories    736938\n",
       "4         British_plays_adapted_into_films  51477341\n",
       "5                   Richard_III_of_England  33466348\n",
       "6                English_Renaissance_plays   1034365\n",
       "7         Use_dmy_dates_from_February_2013  38378953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tdb_0x000001</td>\n",
       "      <td>\"Our Town\" is a play by whom?</td>\n",
       "      <td>Thornton Wilder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Art and literature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Question</td>\n",
       "      <td>False</td>\n",
       "      <td>tdb_0x000001</td>\n",
       "      <td>\"Our Town\" is a play by whom?</td>\n",
       "      <td>0</td>\n",
       "      <td>[Thornton Wilder]</td>\n",
       "      <td>ART_AND_LITERATURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tdb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[Our Town, 0], [play, 150748333]]</td>\n",
       "      <td>[Our Town, play]</td>\n",
       "      <td>True</td>\n",
       "      <td>[SUCCESS]</td>\n",
       "      <td>Our_Town</td>\n",
       "      <td>62695</td>\n",
       "      <td>pages.title  pages.id  intersection  union  \\\n",
       "0  Pulitzer_Prize_for_Drama-winning_works  34794170           NaN    NaN   \n",
       "1                   Theatre_award_winners   7129331           0.0  108.0   \n",
       "2                          Theatre_awards   1975750           0.0   35.0   \n",
       "3                                 Theatre    698600           0.0  147.0   \n",
       "4                         Performing_arts    991222          16.0  258.0   \n",
       "5                           Entertainment    693016          15.0  253.0   \n",
       "6              Main_topic_classifications   7345184           0.0  148.0   \n",
       "\n",
       "    jaccard  depth  similarityBAC mostSimilar  \\\n",
       "0       NaN      5            NaN         NaN   \n",
       "1  0.000000      4            4.0        True   \n",
       "2  0.000000      3            3.0        True   \n",
       "3  0.000000      2            2.0        True   \n",
       "4  0.062016      2           -6.0        True   \n",
       "5  0.059289      1           -6.5        True   \n",
       "6  0.000000      0            0.0       Fals...</td>\n",
       "      <td>pages.title  pages.id\n",
       "0          Drama_Desk_Award-winning_plays  16736972\n",
       "1       American_plays_adapted_into_films  51476012\n",
       "2                Tony_Award-winning_plays  18147375\n",
       "3                Plays_by_Thornton_Wilder  24334082\n",
       "4                          Broadway_plays   2133987\n",
       "5  Pulitzer_Prize_for_Drama-winning_works  34794170\n",
       "6                          West_End_plays  18242373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tdb_0x000002</td>\n",
       "      <td>\"The Diary of Anne Frank\" was first published in English under what title?</td>\n",
       "      <td>The diary of a young girl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Art and literature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Question</td>\n",
       "      <td>False</td>\n",
       "      <td>tdb_0x000002</td>\n",
       "      <td>\"The Diary of Anne Frank\" was first published in English under what title?</td>\n",
       "      <td>0</td>\n",
       "      <td>[The diary of a young girl]</td>\n",
       "      <td>ART_AND_LITERATURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tdb</td>\n",
       "      <td>[tdb_0x006650]</td>\n",
       "      <td>[(The Diary of Anne Frank, WORK_OF_ART), (first, ORDINAL), (English, LANGUAGE)]</td>\n",
       "      <td>[[The Diary of Anne Frank, 0], [title, 196676017]]</td>\n",
       "      <td>[Diary of Anne Frank, Diary of Anne Frank, title]</td>\n",
       "      <td>True</td>\n",
       "      <td>[SUCCESS]</td>\n",
       "      <td>The_Diary_of_a_Young_Girl</td>\n",
       "      <td>1466910</td>\n",
       "      <td>pages.title  pages.id  intersection  union  \\\n",
       "0  Personal_accounts_of_the_Holocaust  22222763           NaN    NaN   \n",
       "1                World_War_II_memoirs  42752119           6.0  153.0   \n",
       "2                    Memoirs_by_topic  37246118           1.0   98.0   \n",
       "3                      Works_by_topic  21046246           0.0  197.0   \n",
       "4                      Creative_works   7390225           0.0  209.0   \n",
       "5                                Arts   4892515           0.0  120.0   \n",
       "6          Main_topic_classifications   7345184           0.0  116.0   \n",
       "\n",
       "    jaccard  depth  similarityBAC mostSimilar  \\\n",
       "0       NaN      5            NaN         NaN   \n",
       "1  0.039216      5            2.0        True   \n",
       "2  0.010204      4            3.5        True   \n",
       "3  0.000000      3            3.0        True   \n",
       "4  0.000000      2            2.0        True   \n",
       "5  0.000000      1            1.0        True   \n",
       "6  0.000000      0            0.0       False   \n",
       "\n",
       "                          ...</td>\n",
       "      <td>pages.title  pages.id\n",
       "0                 Dutch-language_books  54556063\n",
       "1   Personal_accounts_of_the_Holocaust  22222763\n",
       "2      CS1_Dutch-language_sources_(nl)  43966272\n",
       "3                Forgery_controversies  36807531\n",
       "4   CS1_Japanese-language_sources_(ja)  43966204\n",
       "5                 World_War_II_memoirs  42752119\n",
       "6                  Public_domain_books   9394833\n",
       "7         Memory_of_the_World_Register  11945693\n",
       "8         Books_published_posthumously  32947582\n",
       "9                           Anne_Frank   3020256\n",
       "10                   Jewish_literature   3687043\n",
       "11        Books_relating_to_Anne_Frank  31369624\n",
       "12                    Dutch_literature   2685573\n",
       "13            Books_adapted_into_films  24068918\n",
       "14                             Diaries   9519958\n",
       "15         Doubleday_(publisher)_books  40590218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CONS_id  \\\n",
       "0  tdb_0x000000   \n",
       "1  tdb_0x000001   \n",
       "2  tdb_0x000002   \n",
       "\n",
       "                                                                    CONS_question  \\\n",
       "0  \"Now is the winter of our discontent\" is a line from which Shakespearian play?   \n",
       "1                                                   \"Our Town\" is a play by whom?   \n",
       "2      \"The Diary of Anne Frank\" was first published in English under what title?   \n",
       "\n",
       "                 CONS_answer             CONS_alt answers       CONS_category  \\\n",
       "0                Richard III  [Romeo and Juliet, Macbeth]  Art and literature   \n",
       "1            Thornton Wilder                          NaN  Art and literature   \n",
       "2  The diary of a young girl                          NaN  Art and literature   \n",
       "\n",
       "  CONS_alt categories - NOT USED CONS_type-formulation  \\\n",
       "0                            NaN              Question   \n",
       "1                            NaN              Question   \n",
       "2                            NaN              Question   \n",
       "\n",
       "  CONS_type-multipleChoice       ORIG_id  \\\n",
       "0                     True  tdb_0x000000   \n",
       "1                    False  tdb_0x000001   \n",
       "2                    False  tdb_0x000002   \n",
       "\n",
       "                                                                    ORIG_question  \\\n",
       "0  \"Now is the winter of our discontent\" is a line from which Shakespearian play?   \n",
       "1                                                   \"Our Town\" is a play by whom?   \n",
       "2      \"The Diary of Anne Frank\" was first published in English under what title?   \n",
       "\n",
       "  ORIG_answer                          ORIG_alt answers       ORIG_category  \\\n",
       "0           0  [Richard III, Romeo and Juliet, Macbeth]  ART_AND_LITERATURE   \n",
       "1           0                         [Thornton Wilder]  ART_AND_LITERATURE   \n",
       "2           0               [The diary of a young girl]  ART_AND_LITERATURE   \n",
       "\n",
       "  ORIG_alt categories ORIG_difficulty ORIG_type Source Duplicate_removed  \\\n",
       "0                 NaN             NaN       NaN    tdb               NaN   \n",
       "1                 NaN             NaN       NaN    tdb               NaN   \n",
       "2                 NaN             NaN       NaN    tdb    [tdb_0x006650]   \n",
       "\n",
       "                                                                     namedEntities  \\\n",
       "0                                          [(winter, DATE), (Shakespearian, NORP)]   \n",
       "1                                                                               []   \n",
       "2  [(The Diary of Anne Frank, WORK_OF_ART), (first, ORDINAL), (English, LANGUAGE)]   \n",
       "\n",
       "                                                                              nouns  \\\n",
       "0  [[Now is the winter of our discontent, 0], [line, 280009597], [play, 150748333]]   \n",
       "1                                                [[Our Town, 0], [play, 150748333]]   \n",
       "2                                [[The Diary of Anne Frank, 0], [title, 196676017]]   \n",
       "\n",
       "                                         searchTerms  \\\n",
       "0  [Now is the winter of our discontent, play, line]   \n",
       "1                                   [Our Town, play]   \n",
       "2  [Diary of Anne Frank, Diary of Anne Frank, title]   \n",
       "\n",
       "   wikipediaSearchSuccessful findQuestionCategories_meta  \\\n",
       "0                       True                   [SUCCESS]   \n",
       "1                       True                   [SUCCESS]   \n",
       "2                       True                   [SUCCESS]   \n",
       "\n",
       "       wikipediaArticleTitle  wikipediaArticleID  \\\n",
       "0         Richard_III_(play)              176961   \n",
       "1                   Our_Town               62695   \n",
       "2  The_Diary_of_a_Young_Girl             1466910   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              categoryPath  \\\n",
       "0                    pages.title  pages.id  intersection  union   jaccard  depth  \\\n",
       "0   English_Renaissance_plays   1034365           NaN    NaN       NaN      5   \n",
       "1               English_plays   3258485           3.0  703.0  0.004267      5   \n",
       "2               British_plays   1928104          10.0  759.0  0.013175      5   \n",
       "3               British_drama   1376798           3.0  534.0  0.005618      4   \n",
       "4        Drama_by_nationality  25776489           0.0   63.0  0.000000      3   \n",
       "5                       Drama    709071           0.0  115.0  0.000000      2   \n",
       "6                     Theatre    698600           8.0  225.0  0.035556      2   \n",
       "7             Performing_arts    991222          16.0  258.0  0.062016      2   \n",
       "8               Entertainment    693016          15.0  253.0  0.059289      1   \n",
       "9  Main_topic_classifications   7345184           0.0  148.0  0.000000      0   \n",
       "\n",
       "   similarityBAC mostSimilar                             comment  \n",
       "0            NaN         NaN         ...   \n",
       "1                                pages.title  pages.id  intersection  union  \\\n",
       "0  Pulitzer_Prize_for_Drama-winning_works  34794170           NaN    NaN   \n",
       "1                   Theatre_award_winners   7129331           0.0  108.0   \n",
       "2                          Theatre_awards   1975750           0.0   35.0   \n",
       "3                                 Theatre    698600           0.0  147.0   \n",
       "4                         Performing_arts    991222          16.0  258.0   \n",
       "5                           Entertainment    693016          15.0  253.0   \n",
       "6              Main_topic_classifications   7345184           0.0  148.0   \n",
       "\n",
       "    jaccard  depth  similarityBAC mostSimilar  \\\n",
       "0       NaN      5            NaN         NaN   \n",
       "1  0.000000      4            4.0        True   \n",
       "2  0.000000      3            3.0        True   \n",
       "3  0.000000      2            2.0        True   \n",
       "4  0.062016      2           -6.0        True   \n",
       "5  0.059289      1           -6.5        True   \n",
       "6  0.000000      0            0.0       Fals...   \n",
       "2                            pages.title  pages.id  intersection  union  \\\n",
       "0  Personal_accounts_of_the_Holocaust  22222763           NaN    NaN   \n",
       "1                World_War_II_memoirs  42752119           6.0  153.0   \n",
       "2                    Memoirs_by_topic  37246118           1.0   98.0   \n",
       "3                      Works_by_topic  21046246           0.0  197.0   \n",
       "4                      Creative_works   7390225           0.0  209.0   \n",
       "5                                Arts   4892515           0.0  120.0   \n",
       "6          Main_topic_classifications   7345184           0.0  116.0   \n",
       "\n",
       "    jaccard  depth  similarityBAC mostSimilar  \\\n",
       "0       NaN      5            NaN         NaN   \n",
       "1  0.039216      5            2.0        True   \n",
       "2  0.010204      4            3.5        True   \n",
       "3  0.000000      3            3.0        True   \n",
       "4  0.000000      2            2.0        True   \n",
       "5  0.000000      1            1.0        True   \n",
       "6  0.000000      0            0.0       False   \n",
       "\n",
       "                          ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   parentCategories  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                     pages.title  pages.id\n",
       "0   Use_British_English_from_February_2013  38379146\n",
       "1              Plays_about_English_royalty  42128233\n",
       "2  Cultural_depictions_of_English_monarchs  15621221\n",
       "3                  Shakespearean_histories    736938\n",
       "4         British_plays_adapted_into_films  51477341\n",
       "5                   Richard_III_of_England  33466348\n",
       "6                English_Renaissance_plays   1034365\n",
       "7         Use_dmy_dates_from_February_2013  38378953  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                 pages.title  pages.id\n",
       "0          Drama_Desk_Award-winning_plays  16736972\n",
       "1       American_plays_adapted_into_films  51476012\n",
       "2                Tony_Award-winning_plays  18147375\n",
       "3                Plays_by_Thornton_Wilder  24334082\n",
       "4                          Broadway_plays   2133987\n",
       "5  Pulitzer_Prize_for_Drama-winning_works  34794170\n",
       "6                          West_End_plays  18242373  \n",
       "2                             pages.title  pages.id\n",
       "0                 Dutch-language_books  54556063\n",
       "1   Personal_accounts_of_the_Holocaust  22222763\n",
       "2      CS1_Dutch-language_sources_(nl)  43966272\n",
       "3                Forgery_controversies  36807531\n",
       "4   CS1_Japanese-language_sources_(ja)  43966204\n",
       "5                 World_War_II_memoirs  42752119\n",
       "6                  Public_domain_books   9394833\n",
       "7         Memory_of_the_World_Register  11945693\n",
       "8         Books_published_posthumously  32947582\n",
       "9                           Anne_Frank   3020256\n",
       "10                   Jewish_literature   3687043\n",
       "11        Books_relating_to_Anne_Frank  31369624\n",
       "12                    Dutch_literature   2685573\n",
       "13            Books_adapted_into_films  24068918\n",
       "14                             Diaries   9519958\n",
       "15         Doubleday_(publisher)_books  40590218  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchRuns = pd.read_csv(\"../workproduct-files/batchRuns.csv\", delimiter=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startIndex</th>\n",
       "      <th>stopIndex</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>runTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   startIndex  stopIndex  startTime  endTime  runTime\n",
       "0          -1         -1        NaN      NaN      NaN\n",
       "1           0        101        NaN      NaN      NaN\n",
       "2         102        130        NaN      NaN      NaN"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchRuns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startIndex = batchRuns.iloc[-1,1] + 1\n",
    "startIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "useTest = t_data.loc[startIndex : startIndex+batchSize , \"searchTerms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131                                                                                 [tragedy]\n",
       "132                                                           [Piggy, schoolboy, star, story]\n",
       "133                               [fool the eye, illusion, rendering, painting, object, form]\n",
       "134                                           [plaster, lime, technique, fresh, color, water]\n",
       "135    [Europe, antiquity, rebirth, representation, perspective, style, space, form, subject]\n",
       "136    [1940, quallitie, painting, paint, expression, movement, freedom, surface, act, value]\n",
       "137                                          [Catcher in the Rye, Catcher in the Rye, author]\n",
       "138                                      [Doctor Zhivago, novel, society, author, view, time]\n",
       "139                                                                                  [writer]\n",
       "140                                                                      [artist, art, world]\n",
       "141                         [Shakespeare, plot, wife, king, summary, play, man, place, order]\n",
       "Name: searchTerms, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.gmtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.mktime(ts2)-time.mktime(ts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = time.gmtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts2 = time.gmtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference = time.mktime(ts2)-time.mktime(ts1)\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-23 10:54:09\n",
      "2020-09-23 10:54:31\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", ts1))\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", ts2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTerms1 = []\n",
    "testTerms2 = [\"asdfölakjhsg\", \"asdgiieieiei\"]\n",
    "testTerms3 = [\"meaning\", \"wood\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findQuestionCategories(testTerms1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findQuestionCategories(testTerms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findQuestionCategories(testTerms3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT: Batch runs\n",
    "# Save correct version of t_data (with key words identified) to dedicated folder\n",
    "# Create text file with index to start next batch (0)\n",
    "# Run batch as .apply(lambda x: [TERMS].findQuestionCategories(x)) on n rows\n",
    "# Save output (with indexes intact) as pickle in subfolder\n",
    "# Update text file with index + n\n",
    "\n",
    "# ITERATE FULL DATA SET\n",
    "\n",
    "# Combine all files with rows\n",
    "# Append result rows to t_data dataset\n",
    "\n",
    "# Perform categorization based on all existing info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
